{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample random frames from celticsheat.mp4\n",
    "# save to temp.mp4\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "# get video\n",
    "cap = cv2.VideoCapture('celticsheat.mp4')\n",
    "\n",
    "# get frame count\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# get frame rate\n",
    "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# get frame width\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# get frame height\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# get frame size\n",
    "frame_size = (frame_width, frame_height)\n",
    "\n",
    "# get frame duration\n",
    "frame_duration = 1 / frame_rate\n",
    "\n",
    "# get video duration\n",
    "video_duration = frame_count * frame_duration\n",
    "\n",
    "# get random frame numbers\n",
    "random_frame_numbers = random.sample(range(0, frame_count), 100)\n",
    "\n",
    "# get random frame times\n",
    "random_frame_times = [x * frame_duration for x in random_frame_numbers]\n",
    "\n",
    "# get random frame positions\n",
    "random_frame_positions = [int(x * frame_rate) for x in random_frame_times]\n",
    "\n",
    "# set video writer\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "# set output file\n",
    "output_file = 'temp.mp4'\n",
    "\n",
    "# set output path\n",
    "output_path = os.path.join(os.getcwd(), output_file)\n",
    "\n",
    "# set output video\n",
    "out = cv2.VideoWriter(output_path, fourcc, frame_rate, frame_size)\n",
    "\n",
    "# loop through random frame positions\n",
    "for i in random_frame_positions:\n",
    "    # set frame position\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "    \n",
    "    # read frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # write frame\n",
    "    out.write(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/models/yolos/feature_extraction_yolos.py:28: FutureWarning: The class YolosFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use YolosImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.10.4/lib/python3.10/site-packages/transformers/models/yolos/image_processing_yolos.py:704: FutureWarning: The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import YolosFeatureExtractor, YolosForObjectDetection\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "feature_extractor = YolosFeatureExtractor.from_pretrained('hustvl/yolos-tiny')\n",
    "model = YolosForObjectDetection.from_pretrained('hustvl/yolos-tiny')\n",
    "\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# model predicts bounding boxes and corresponding COCO classes\n",
    "logits = outputs.logits\n",
    "bboxes = outputs.pred_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "video_path = 'celticsheat.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Define the video writer object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "# Process each frame of the video\n",
    "while cap.isOpened():\n",
    "    time.sleep(0.1)\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Break the loop if no more frames are available\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to a PIL Image\n",
    "    image = Image.fromarray(frame)\n",
    "\n",
    "    # Perform object detection on the image\n",
    "    inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Extract the predicted bounding boxes\n",
    "    logits = outputs.logits\n",
    "    bboxes = outputs.pred_boxes\n",
    "\n",
    "    # Draw the predicted bounding boxes on the frame\n",
    "    for bbox in bboxes:\n",
    "        x1, y1, x2, y2 = bbox.tolist()\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "\n",
    "    # Write the frame with bounding boxes to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the video capture and writer objects\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('celticsheat.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
